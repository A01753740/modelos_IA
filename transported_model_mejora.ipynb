{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.drop(columns=['Name'],inplace=True)\n",
    "train['Transported'] = train['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[amenities] = train[amenities].fillna(0)\n",
    "train['Amenities'] = train[amenities].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['GroupId', 'PassengerNumber']] = train['PassengerId'].str.split('_', expand=True)\n",
    "train['PassengerNumber'] = train['PassengerNumber'].astype(int)\n",
    "train['GroupId'] = train['GroupId'].astype(int)\n",
    "train.drop(columns=['PassengerId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Zone', 'Seat', 'Side']] = train['Cabin'].str.split('/', expand=True)\n",
    "train.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Amenities</th>\n",
       "      <th>GroupId</th>\n",
       "      <th>PassengerNumber</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Seat</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>736.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet CryoSleep  Destination   Age    VIP  RoomService  FoodCourt  \\\n",
       "0     Europa     False  TRAPPIST-1e  39.0  False          0.0        0.0   \n",
       "1      Earth     False  TRAPPIST-1e  24.0  False        109.0        9.0   \n",
       "2     Europa     False  TRAPPIST-1e  58.0   True         43.0     3576.0   \n",
       "3     Europa     False  TRAPPIST-1e  33.0  False          0.0     1283.0   \n",
       "4      Earth     False  TRAPPIST-1e  16.0  False        303.0       70.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  Transported  Amenities  GroupId  \\\n",
       "0           0.0     0.0     0.0            0        0.0        1   \n",
       "1          25.0   549.0    44.0            1      736.0        2   \n",
       "2           0.0  6715.0    49.0            0    10383.0        3   \n",
       "3         371.0  3329.0   193.0            0     5176.0        3   \n",
       "4         151.0   565.0     2.0            1     1091.0        4   \n",
       "\n",
       "   PassengerNumber Zone Seat Side  \n",
       "0                1    B    0    P  \n",
       "1                1    F    0    S  \n",
       "2                1    A    0    S  \n",
       "3                2    A    0    S  \n",
       "4                1    F    1    S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet         201\n",
       "CryoSleep          217\n",
       "Destination        182\n",
       "Age                179\n",
       "VIP                203\n",
       "RoomService          0\n",
       "FoodCourt            0\n",
       "ShoppingMall         0\n",
       "Spa                  0\n",
       "VRDeck               0\n",
       "Transported          0\n",
       "Amenities            0\n",
       "GroupId              0\n",
       "PassengerNumber      0\n",
       "Zone               199\n",
       "Seat               199\n",
       "Side               199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HomePlanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/2865644417.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['HomePlanet']= train['HomePlanet'].replace('Europa',2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HomePlanet\n",
       "0.0    4602\n",
       "2.0    2131\n",
       "1.0    1759\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['HomePlanet']= train['HomePlanet'].replace('Earth',0)\n",
    "train['HomePlanet']= train['HomePlanet'].replace('Mars',1)\n",
    "train['HomePlanet']= train['HomePlanet'].replace('Europa',2)\n",
    "train['HomePlanet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en HomePlanet:\n",
      "HomePlanet\n",
      "0.0    52.94\n",
      "2.0    24.51\n",
      "1.0    20.23\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de HomePlanet = Earth:\n",
      "RoomService     133.875272\n",
      "FoodCourt       134.336375\n",
      "ShoppingMall    130.614515\n",
      "Spa             139.710126\n",
      "VRDeck          134.801173\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de HomePlanet = Mars:\n",
      "RoomService     541.581580\n",
      "FoodCourt        53.187607\n",
      "ShoppingMall    302.133030\n",
      "Spa             107.965890\n",
      "VRDeck           46.388857\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de HomePlanet = Europa:\n",
      "RoomService      142.778508\n",
      "FoodCourt       1470.764430\n",
      "ShoppingMall     147.374003\n",
      "Spa              830.147349\n",
      "VRDeck           860.560300\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de HomePlanet = ???:\n",
      "RoomService     196.736318\n",
      "FoodCourt       260.024876\n",
      "ShoppingMall    136.805970\n",
      "Spa             228.303483\n",
      "VRDeck          283.497512\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en HomePlanet:')\n",
    "print(round(train['HomePlanet'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de HomePlanet = Earth:')\n",
    "print(train[train['HomePlanet'] == 0][amenities].mean())\n",
    "print('\\nPagos en amenidades de HomePlanet = Mars:')\n",
    "print(train[train['HomePlanet'] == 1][amenities].mean())\n",
    "print('\\nPagos en amenidades de HomePlanet = Europa:')\n",
    "print(train[train['HomePlanet'] == 2][amenities].mean())\n",
    "print('\\nPagos en amenidades de HomePlanet = ???:')\n",
    "print(train[train['HomePlanet'].isna()][amenities].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en HomePlanet:\n",
      "HomePlanet\n",
      "0.0    52.94\n",
      "2.0    24.51\n",
      "1.0    20.23\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de HomePlanet = Earth:\n",
      "673.3374619730552\n",
      "\n",
      "Pagos en amenidades de HomePlanet = Mars:\n",
      "1051.2569641841956\n",
      "\n",
      "Pagos en amenidades de HomePlanet = Europa:\n",
      "3451.6245893946502\n",
      "\n",
      "Pagos en amenidades de HomePlanet = ???:\n",
      "1105.3681592039802\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en HomePlanet:')\n",
    "print(round(train['HomePlanet'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de HomePlanet = Earth:')\n",
    "print(train[train['HomePlanet'] == 0]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de HomePlanet = Mars:')\n",
    "print(train[train['HomePlanet'] == 1]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de HomePlanet = Europa:')\n",
    "print(train[train['HomePlanet'] == 2]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de HomePlanet = ???:')\n",
    "print(train[train['HomePlanet'].isna()]['Amenities'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['HomePlanet'] = train['HomePlanet'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['HomePlanet'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet\n",
       "0.0    4602\n",
       "2.0    2131\n",
       "1.0    1960\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['HomePlanet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CryoSleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en CryoSleep:\n",
      "CryoSleep\n",
      "False    62.57\n",
      "True     34.94\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de quienes están en CryoSleep:\n",
      "RoomService     0.0\n",
      "FoodCourt       0.0\n",
      "ShoppingMall    0.0\n",
      "Spa             0.0\n",
      "VRDeck          0.0\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de quienes NO están en CryoSleep:\n",
      "RoomService     343.000919\n",
      "FoodCourt       698.584299\n",
      "ShoppingMall    265.412576\n",
      "Spa             475.993933\n",
      "VRDeck          465.307961\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en CryoSleep:')\n",
    "print(round(train['CryoSleep'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de quienes están en CryoSleep:')\n",
    "print(train[train['CryoSleep'] == True][amenities].mean())\n",
    "print('\\nPagos en amenidades de quienes NO están en CryoSleep:')\n",
    "print(train[train['CryoSleep'] == False][amenities].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/139052112.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['CryoSleep'] = train['CryoSleep'].fillna(train.apply(lambda row: False if any(row[amenities] > 0) else True, axis=1))\n"
     ]
    }
   ],
   "source": [
    "train['CryoSleep'] = train['CryoSleep'].fillna(train.apply(lambda row: False if any(row[amenities] > 0) else True, axis=1))\n",
    "train['CryoSleep'] = train['CryoSleep'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CryoSleep\n",
       "False    5558\n",
       "True     3135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['CryoSleep'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Destination\n",
       "TRAPPIST-1e      5915\n",
       "55 Cancri e      1800\n",
       "PSO J318.5-22     796\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Destination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/1204826497.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['Destination']= train['Destination'].replace('PSO J318.5-22',2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Destination\n",
       "0.0    5915\n",
       "1.0    1800\n",
       "2.0     796\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Destination']= train['Destination'].replace('TRAPPIST-1e',0)\n",
    "train['Destination']= train['Destination'].replace('55 Cancri e',1)\n",
    "train['Destination']= train['Destination'].replace('PSO J318.5-22',2)\n",
    "train['Destination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en Destination:\n",
      "Destination\n",
      "0.0    68.04\n",
      "1.0    20.71\n",
      "2.0     9.16\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de Destination = TRAPPIST-1e:\n",
      "RoomService     247.476923\n",
      "FoodCourt       368.035503\n",
      "ShoppingMall    183.121386\n",
      "Spa             277.980558\n",
      "VRDeck          261.725613\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Destination = 55 Cancri e:\n",
      "RoomService     189.712222\n",
      "FoodCourt       869.836667\n",
      "ShoppingMall    153.495000\n",
      "Spa             469.986667\n",
      "VRDeck          497.255000\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Destination = PSO J318.5-22:\n",
      "RoomService      88.211055\n",
      "FoodCourt       119.731156\n",
      "ShoppingMall    110.723618\n",
      "Spa             115.629397\n",
      "VRDeck          138.020101\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Destination = ???:\n",
      "RoomService     203.390110\n",
      "FoodCourt       331.291209\n",
      "ShoppingMall    145.615385\n",
      "Spa             359.994505\n",
      "VRDeck          218.461538\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en Destination:')\n",
    "print(round(train['Destination'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de Destination = TRAPPIST-1e:')\n",
    "print(train[train['Destination'] == 0][amenities].mean())\n",
    "print('\\nPagos en amenidades de Destination = 55 Cancri e:')\n",
    "print(train[train['Destination'] == 1][amenities].mean())\n",
    "print('\\nPagos en amenidades de Destination = PSO J318.5-22:')\n",
    "print(train[train['Destination'] == 2][amenities].mean())\n",
    "print('\\nPagos en amenidades de Destination = ???:')\n",
    "print(train[train['Destination'].isna()][amenities].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en Destination:\n",
      "Destination\n",
      "0.0    68.04\n",
      "1.0    20.71\n",
      "2.0     9.16\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de Destination = TRAPPIST-1e:\n",
      "1338.3399830938292\n",
      "\n",
      "Pagos en amenidades de Destination = 55 Cancri e:\n",
      "2180.2855555555557\n",
      "\n",
      "Pagos en amenidades de Destination = PSO J318.5-22:\n",
      "572.3153266331658\n",
      "\n",
      "Pagos en amenidades de Destination = ???:\n",
      "1258.7527472527472\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en Destination:')\n",
    "print(round(train['Destination'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de Destination = TRAPPIST-1e:')\n",
    "print(train[train['Destination'] == 0]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Destination = 55 Cancri e:')\n",
    "print(train[train['Destination'] == 1]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Destination = PSO J318.5-22:')\n",
    "print(train[train['Destination'] == 2]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Destination = ???:')\n",
    "print(train[train['Destination'].isna()]['Amenities'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Destination'] = train['Destination'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_group'] = np.where(pd.isna(train['Age']), np.nan, np.where(train['Age'] < 18, 0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "1.0    6969\n",
       "0.0    1545\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en age_group:\n",
      "age_group\n",
      "1.0    80.17\n",
      "0.0    17.77\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de age_group = Menor de edad:\n",
      "398.93203883495147\n",
      "\n",
      "Pagos en amenidades de age_group = Mayor de edad:\n",
      "1675.551729085952\n",
      "\n",
      "Pagos en amenidades de age_group = ???:\n",
      "1297.1005586592178\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en age_group:')\n",
    "print(round(train['age_group'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de age_group = Menor de edad:')\n",
    "print(train[train['age_group'] == 0]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de age_group = Mayor de edad:')\n",
    "print(train[train['age_group'] == 1]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de age_group = ???:')\n",
    "print(train[train['age_group'].isna()]['Amenities'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en age_group:\n",
      "age_group\n",
      "1.0    80.17\n",
      "0.0    17.77\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de age_group = Menor de edad:\n",
      "RoomService      97.444013\n",
      "FoodCourt        70.911327\n",
      "ShoppingMall    106.266667\n",
      "Spa              64.220065\n",
      "VRDeck           60.089968\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de age_group = Mayor de edad:\n",
      "RoomService     248.572679\n",
      "FoodCourt       533.184818\n",
      "ShoppingMall    185.404649\n",
      "Spa             356.714737\n",
      "VRDeck          351.674846\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de age_group = ???:\n",
      "RoomService     165.849162\n",
      "FoodCourt       407.340782\n",
      "ShoppingMall     99.581006\n",
      "Spa             349.865922\n",
      "VRDeck          274.463687\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en age_group:')\n",
    "print(round(train['age_group'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de age_group = Menor de edad:')\n",
    "print(train[train['age_group'] == 0][amenities].mean())\n",
    "print('\\nPagos en amenidades de age_group = Mayor de edad:')\n",
    "print(train[train['age_group'] == 1][amenities].mean())\n",
    "print('\\nPagos en amenidades de age_group = ???:')\n",
    "print(train[train['age_group'].isna()][amenities].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_group'] = train['age_group'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Age'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VIP\n",
       "False    8291\n",
       "True      199\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['VIP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en VIP:\n",
      "VIP\n",
      "False    95.38\n",
      "True      2.29\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de VIP = False:\n",
      "RoomService     212.686045\n",
      "FoodCourt       417.440598\n",
      "ShoppingMall    169.702931\n",
      "Spa             295.197202\n",
      "VRDeck          276.477868\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de VIP = True:\n",
      "RoomService      464.095477\n",
      "FoodCourt       1756.778894\n",
      "ShoppingMall     241.502513\n",
      "Spa              753.065327\n",
      "VRDeck          1210.035176\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de VIP = ???:\n",
      "RoomService     279.832512\n",
      "FoodCourt       431.714286\n",
      "ShoppingMall     93.724138\n",
      "Spa             248.527094\n",
      "VRDeck          294.162562\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en VIP:')\n",
    "print(round(train['VIP'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de VIP = False:')\n",
    "print(train[train['VIP'] == 0][amenities].mean())\n",
    "print('\\nPagos en amenidades de VIP = True:')\n",
    "print(train[train['VIP'] == 1][amenities].mean())\n",
    "print('\\nPagos en amenidades de VIP = ???:')\n",
    "print(train[train['VIP'].isna()][amenities].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en VIP:\n",
      "VIP\n",
      "False    95.38\n",
      "True      2.29\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de VIP = False:\n",
      "1371.5046435894344\n",
      "\n",
      "Pagos en amenidades de VIP = True:\n",
      "4425.477386934674\n",
      "\n",
      "Pagos en amenidades de VIP = ???:\n",
      "1347.960591133005\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en VIP:')\n",
    "print(round(train['VIP'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de VIP = False:')\n",
    "print(train[train['VIP'] == 0]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de VIP = True:')\n",
    "print(train[train['VIP'] == 1]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de VIP = ???:')\n",
    "print(train[train['VIP'].isna()]['Amenities'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['VIP'] = train['VIP'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['VIP'] = train['VIP'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zone, Seat, Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Side\n",
       "S    4288\n",
       "P    4206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Side'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/1685123017.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['Side'] = train['Side'].replace('P',1)\n"
     ]
    }
   ],
   "source": [
    "train['Side'] = train['Side'].replace('S',0)\n",
    "train['Side'] = train['Side'].replace('P',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en Side:\n",
      "Side\n",
      "0.0    49.33\n",
      "1.0    48.38\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de Side = S:\n",
      "1441.298041044776\n",
      "\n",
      "Pagos en amenidades de Side = P:\n",
      "1430.1507370423205\n",
      "\n",
      "Pagos en amenidades de Side = ???:\n",
      "1658.0452261306532\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en Side:')\n",
    "print(round(train['Side'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de Side = S:')\n",
    "print(train[train['Side'] == 0]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Side = P:')\n",
    "print(train[train['Side'] == 1]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Side = ???:')\n",
    "print(train[train['Side'].isna()]['Amenities'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en Side:\n",
      "Side\n",
      "0.0    49.33\n",
      "1.0    48.38\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de Side = S:\n",
      "False\n",
      "\n",
      "Pagos en amenidades de Side = P:\n",
      "False\n",
      "\n",
      "Pagos en amenidades de Side = ???:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en Side:')\n",
    "print(round(train['Side'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de Side = S:')\n",
    "print(train[train['Side'] == 0]['CryoSleep'].mode()[0])\n",
    "print('\\nPagos en amenidades de Side = P:')\n",
    "print(train[train['Side'] == 1]['CryoSleep'].mode()[0])\n",
    "print('\\nPagos en amenidades de Side = ???:')\n",
    "print(train[train['Side'].isna()]['CryoSleep'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "1.0    3507\n",
       "0.0     781\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Side'] == 0]['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "1.0    3481\n",
       "0.0     725\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Side'] == 1]['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "1.0    160\n",
       "0.0     39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Side'].isna()]['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mitad 0, mitad 1 debido a que la distribución en todas las variables es casi idéntica\n",
    "nan_indices = train[train['Side'].isna()].index\n",
    "\n",
    "# Convertir los índices a una lista para hacerlos mutables\n",
    "nan_indices_list = list(nan_indices)\n",
    "\n",
    "# Mezclar aleatoriamente los índices\n",
    "np.random.shuffle(nan_indices_list)\n",
    "\n",
    "# Dividir los índices en dos mitades\n",
    "half = len(nan_indices_list) // 2\n",
    "\n",
    "# Asignar 0 a la primera mitad y 1 a la segunda mitad\n",
    "train.loc[nan_indices_list[:half], 'Side'] = 0\n",
    "train.loc[nan_indices_list[half:], 'Side'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zone\n",
       "F    2794\n",
       "G    2559\n",
       "E     876\n",
       "B     779\n",
       "C     747\n",
       "D     478\n",
       "A     256\n",
       "T       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Zone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Zone'].replace('G', 0, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Zone'].replace('F', 1, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Zone'].replace('E', 2, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Zone'].replace('D', 3, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Zone'].replace('B', 4, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Zone'].replace('A', 5, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Zone'].replace('C', 6, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Zone'].replace('T', 7, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_11644/3872317236.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['Zone'].replace('T', 7, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train['Zone'].replace('G', 0, inplace=True)\n",
    "train['Zone'].replace('F', 1, inplace=True)\n",
    "train['Zone'].replace('E', 2, inplace=True)\n",
    "train['Zone'].replace('D', 3, inplace=True)\n",
    "train['Zone'].replace('B', 4, inplace=True)\n",
    "train['Zone'].replace('A', 5, inplace=True)\n",
    "train['Zone'].replace('C', 6, inplace=True)\n",
    "train['Zone'].replace('T', 7, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en Zone:\n",
      "Zone\n",
      "1.0    32.14\n",
      "0.0    29.44\n",
      "2.0    10.08\n",
      "4.0     8.96\n",
      "6.0     8.59\n",
      "3.0     5.50\n",
      "5.0     2.94\n",
      "7.0     0.06\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 0:\n",
      "381.03516998827666\n",
      "\n",
      "Pagos en amenidades de Zone = 1:\n",
      "982.7662848962061\n",
      "\n",
      "Pagos en amenidades de Zone = 2:\n",
      "1298.7728310502282\n",
      "\n",
      "Pagos en amenidades de Zone = 3:\n",
      "2289.520920502092\n",
      "\n",
      "Pagos en amenidades de Zone = 4:\n",
      "2927.8331193838253\n",
      "\n",
      "Pagos en amenidades de Zone = 5:\n",
      "3402.3046875\n",
      "\n",
      "Pagos en amenidades de Zone = 6:\n",
      "4105.906291834002\n",
      "\n",
      "Pagos en amenidades de Zone = 7:\n",
      "4716.4\n",
      "\n",
      "Pagos en amenidades de Zone = ???:\n",
      "1658.0452261306532\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en Zone:')\n",
    "print(round(train['Zone'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de Zone = 0:')\n",
    "print(train[train['Zone'] == 0]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Zone = 1:')\n",
    "print(train[train['Zone'] == 1]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Zone = 2:')\n",
    "print(train[train['Zone'] == 2]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Zone = 3:')\n",
    "print(train[train['Zone'] == 3]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Zone = 4:')\n",
    "print(train[train['Zone'] == 4]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Zone = 5:')\n",
    "print(train[train['Zone'] == 5]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Zone = 6:')\n",
    "print(train[train['Zone'] == 6]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Zone = 7:')\n",
    "print(train[train['Zone'] == 7]['Amenities'].mean())\n",
    "print('\\nPagos en amenidades de Zone = ???:')\n",
    "print(train[train['Zone'].isna()]['Amenities'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de personas en Zone:\n",
      "Zone\n",
      "1.0    32.14\n",
      "0.0    29.44\n",
      "2.0    10.08\n",
      "4.0     8.96\n",
      "6.0     8.59\n",
      "3.0     5.50\n",
      "5.0     2.94\n",
      "7.0     0.06\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 0:\n",
      "RoomService     71.439625\n",
      "FoodCourt       78.076592\n",
      "ShoppingMall    69.087143\n",
      "Spa             87.917937\n",
      "VRDeck          74.513873\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 1:\n",
      "RoomService     302.185755\n",
      "FoodCourt       142.406586\n",
      "ShoppingMall    234.280243\n",
      "Spa             161.430565\n",
      "VRDeck          142.463135\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 2:\n",
      "RoomService     306.692922\n",
      "FoodCourt       263.061644\n",
      "ShoppingMall    226.280822\n",
      "Spa             265.131279\n",
      "VRDeck          237.606164\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 3:\n",
      "RoomService     660.018828\n",
      "FoodCourt       581.583682\n",
      "ShoppingMall    305.476987\n",
      "Spa             460.830544\n",
      "VRDeck          281.610879\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 4:\n",
      "RoomService       84.148909\n",
      "FoodCourt       1238.555841\n",
      "ShoppingMall     149.083440\n",
      "Spa              714.468549\n",
      "VRDeck           741.576380\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 5:\n",
      "RoomService      133.039062\n",
      "FoodCourt       1541.539062\n",
      "ShoppingMall     110.062500\n",
      "Spa              693.250000\n",
      "VRDeck           924.414062\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 6:\n",
      "RoomService      178.016064\n",
      "FoodCourt       1788.607764\n",
      "ShoppingMall     171.340027\n",
      "Spa              905.384203\n",
      "VRDeck          1062.558233\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = 7:\n",
      "RoomService      427.2\n",
      "FoodCourt       1397.4\n",
      "ShoppingMall       0.4\n",
      "Spa             2008.4\n",
      "VRDeck           883.0\n",
      "dtype: float64\n",
      "\n",
      "Pagos en amenidades de Zone = ???:\n",
      "RoomService     334.391960\n",
      "FoodCourt       450.100503\n",
      "ShoppingMall    131.527638\n",
      "Spa             496.648241\n",
      "VRDeck          245.376884\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de personas en Zone:')\n",
    "print(round(train['Zone'].value_counts() / len(train) * 100, 2))\n",
    "\n",
    "print('\\nPagos en amenidades de Zone = 0:')\n",
    "print(train[train['Zone'] == 0][amenities].mean())\n",
    "print('\\nPagos en amenidades de Zone = 1:')\n",
    "print(train[train['Zone'] == 1][amenities].mean())\n",
    "print('\\nPagos en amenidades de Zone = 2:')\n",
    "print(train[train['Zone'] == 2][amenities].mean())\n",
    "print('\\nPagos en amenidades de Zone = 3:')\n",
    "print(train[train['Zone'] == 3][amenities].mean())\n",
    "print('\\nPagos en amenidades de Zone = 4:')\n",
    "print(train[train['Zone'] == 4][amenities].mean())\n",
    "print('\\nPagos en amenidades de Zone = 5:')\n",
    "print(train[train['Zone'] == 5][amenities].mean())\n",
    "print('\\nPagos en amenidades de Zone = 6:')\n",
    "print(train[train['Zone'] == 6][amenities].mean())\n",
    "print('\\nPagos en amenidades de Zone = 7:')\n",
    "print(train[train['Zone'] == 7][amenities].mean())\n",
    "print('\\nPagos en amenidades de Zone = ???:')\n",
    "print(train[train['Zone'].isna()][amenities].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_means = {\n",
    "    0: np.array([71.439625, 78.076592, 69.087143, 87.917937, 74.513873]),\n",
    "    1: np.array([302.185755, 142.406586, 234.280243, 161.430565, 142.463135]),\n",
    "    2: np.array([306.692922, 263.061644, 226.280822, 265.131279, 237.606164]),\n",
    "    3: np.array([660.018828, 581.583682, 305.476987, 460.830544, 281.610879]),\n",
    "    4: np.array([84.148909, 1238.555841, 149.083440, 714.468549, 741.576380]),\n",
    "    5: np.array([133.039062, 1541.539062, 110.062500, 693.250000, 924.414062]),\n",
    "    6: np.array([178.016064, 1788.607764, 171.340027, 905.384203, 1062.558233]),\n",
    "    7: np.array([427.2, 1397.4, 0.4, 2008.4, 883.0])\n",
    "}\n",
    "\n",
    "# Calcular la suma de las amenidades para las filas con Zone NaN\n",
    "train['amenity_sum'] = train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "\n",
    "# Para las filas con Zone NaN, asignar la zona basada en la cercanía a los promedios\n",
    "def assign_zone(row):\n",
    "    if pd.isna(row['Zone']):\n",
    "        amenity_values = row[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].values\n",
    "        # Calcular la distancia euclidiana entre los pagos y los promedios de cada zona\n",
    "        distances = {zone: np.linalg.norm(amenity_values - means) for zone, means in zone_means.items()}\n",
    "        # Asignar la zona con la menor distancia\n",
    "        return min(distances, key=distances.get)\n",
    "    return row['Zone']\n",
    "\n",
    "# Aplicar la función para asignar las zonas\n",
    "train['Zone'] = train.apply(assign_zone, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Seat','amenity_sum'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando mejores hiperparámetros para XGBoost...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Mejores hiperparámetros para XGBoost: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Buscando mejores hiperparámetros para CatBoost...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Mejores hiperparámetros para CatBoost: {'depth': 7, 'iterations': 200, 'learning_rate': 0.1}\n",
      "Buscando mejores hiperparámetros para LightGBM...\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2191, number of negative: 2155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504142 -> initscore=0.016567\n",
      "[LightGBM] [Info] Start training from score 0.016567\n",
      "[LightGBM] [Info] Number of positive: 2190, number of negative: 2156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 4346, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503912 -> initscore=0.015647\n",
      "[LightGBM] [Info] Start training from score 0.015647\n",
      "[LightGBM] [Info] Number of positive: 3286, number of negative: 3233\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 6519, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504065 -> initscore=0.016261\n",
      "[LightGBM] [Info] Start training from score 0.016261\n",
      "Mejores hiperparámetros para LightGBM: {'learning_rate': 0.1, 'n_estimators': 50, 'num_leaves': 31}\n",
      "Buscando mejores hiperparámetros para RandomForest...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Mejores hiperparámetros para RandomForest: {'max_depth': 9, 'n_estimators': 200}\n",
      "Buscando mejores hiperparámetros para LogisticRegression...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para LogisticRegression: {'C': 0.1, 'max_iter': 300, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "[LightGBM] [Info] Number of positive: 3286, number of negative: 3233\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1816\n",
      "[LightGBM] [Info] Number of data points in the train set: 6519, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504065 -> initscore=0.016261\n",
      "[LightGBM] [Info] Start training from score 0.016261\n",
      "Accuracy del Voting Classifier: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      1082\n",
      "           1       0.78      0.84      0.81      1092\n",
      "\n",
      "    accuracy                           0.80      2174\n",
      "   macro avg       0.80      0.80      0.80      2174\n",
      "weighted avg       0.80      0.80      0.80      2174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generar un dataset de ejemplo\n",
    "X = train.drop(columns=['Transported'])\n",
    "y = train['Transported']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Definir los parámetros para GridSearchCV para cada modelo\n",
    "\n",
    "# Parámetros para XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Parámetros para CatBoost\n",
    "catboost_params = {\n",
    "    'iterations': [50, 100, 200],\n",
    "    'depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Parámetros para LightGBM\n",
    "lgbm_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'num_leaves': [31, 50],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Parámetros para RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# Parámetros para LogisticRegression\n",
    "lr_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "\n",
    "# Definir los clasificadores base sin ajuste\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "catboost = CatBoostClassifier(verbose=0, random_state=42)\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Realizar el GridSearchCV para cada modelo\n",
    "print(\"Buscando mejores hiperparámetros para XGBoost...\")\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=3, scoring='accuracy', verbose=1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "print(f\"Mejores hiperparámetros para XGBoost: {xgb_grid.best_params_}\")\n",
    "\n",
    "print(\"Buscando mejores hiperparámetros para CatBoost...\")\n",
    "catboost_grid = GridSearchCV(catboost, catboost_params, cv=3, scoring='accuracy', verbose=1)\n",
    "catboost_grid.fit(X_train, y_train)\n",
    "print(f\"Mejores hiperparámetros para CatBoost: {catboost_grid.best_params_}\")\n",
    "\n",
    "print(\"Buscando mejores hiperparámetros para LightGBM...\")\n",
    "lgbm_grid = GridSearchCV(lgbm, lgbm_params, cv=3, scoring='accuracy', verbose=1)\n",
    "lgbm_grid.fit(X_train, y_train)\n",
    "print(f\"Mejores hiperparámetros para LightGBM: {lgbm_grid.best_params_}\")\n",
    "\n",
    "# Realizar el GridSearchCV para RandomForest\n",
    "print(\"Buscando mejores hiperparámetros para RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='accuracy', verbose=1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(f\"Mejores hiperparámetros para RandomForest: {rf_grid.best_params_}\")\n",
    "\n",
    "# Realizar el GridSearchCV para LogisticRegression\n",
    "print(\"Buscando mejores hiperparámetros para LogisticRegression...\")\n",
    "lr_grid = GridSearchCV(lr, lr_params, cv=3, scoring='accuracy', verbose=1)\n",
    "lr_grid.fit(X_train, y_train)\n",
    "print(f\"Mejores hiperparámetros para LogisticRegression: {lr_grid.best_params_}\")\n",
    "\n",
    "# Usar los mejores modelos en el VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('xgb', xgb_grid.best_estimator_),\n",
    "    ('catboost', catboost_grid.best_estimator_),\n",
    "    ('lgbm', lgbm_grid.best_estimator_),\n",
    "    ('rf', rf_grid.best_estimator_),\n",
    "    ('lr', lr_grid.best_estimator_)\n",
    "], voting='hard')  # Puedes cambiar a 'soft' si deseas usar promedios de probabilidades\n",
    "\n",
    "# Entrenar el VotingClassifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy del Voting Classifier: {accuracy:.2f}\")\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar el reporte de clasificación\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;logloss&#x27;,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learni...\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=42, ...)),\n",
       "                             (&#x27;catboost&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x369dfcb60&gt;),\n",
       "                             (&#x27;lgbm&#x27;,\n",
       "                              LGBMClassifier(n_estimators=50, random_state=42)),\n",
       "                             (&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(max_depth=9,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=0.1, max_iter=300,\n",
       "                                                 random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;VotingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;logloss&#x27;,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learni...\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=42, ...)),\n",
       "                             (&#x27;catboost&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x369dfcb60&gt;),\n",
       "                             (&#x27;lgbm&#x27;,\n",
       "                              LGBMClassifier(n_estimators=50, random_state=42)),\n",
       "                             (&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(max_depth=9,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=0.1, max_iter=300,\n",
       "                                                 random_state=42))])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>catboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x369dfcb60&gt;</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(n_estimators=50, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=9, n_estimators=200, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, max_iter=300, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric='logloss',\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learni...\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=42, ...)),\n",
       "                             ('catboost',\n",
       "                              <catboost.core.CatBoostClassifier object at 0x369dfcb60>),\n",
       "                             ('lgbm',\n",
       "                              LGBMClassifier(n_estimators=50, random_state=42)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=9,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=0.1, max_iter=300,\n",
       "                                                 random_state=42))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.drop(columns=['Name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "test[amenities] = test[amenities].fillna(0)\n",
    "test['Amenities'] = test[amenities].sum(axis=1)\n",
    "\n",
    "test[['GroupId', 'PassengerNumber']] = test['PassengerId'].str.split('_', expand=True)\n",
    "test['PassengerNumber'] = test['PassengerNumber'].astype(int)\n",
    "test['GroupId'] = test['GroupId'].astype(int)\n",
    "test.drop(columns=['PassengerId'],inplace=True)\n",
    "\n",
    "test[['Zone', 'Seat', 'Side']] = test['Cabin'].str.split('/', expand=True)\n",
    "test.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['HomePlanet']= test['HomePlanet'].replace('Europa',2)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:8: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['CryoSleep'] = test['CryoSleep'].fillna(test.apply(lambda row: False if any(row[amenities] > 0) else True, axis=1))\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['Destination']= test['Destination'].replace('PSO J318.5-22',2)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['Side'] = test['Side'].replace('P',1)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Zone'].replace('G', 0, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:45: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Zone'].replace('F', 1, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Zone'].replace('E', 2, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Zone'].replace('D', 3, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Zone'].replace('B', 4, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Zone'].replace('A', 5, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Zone'].replace('C', 6, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Zone'].replace('T', 7, inplace=True)\n",
      "/var/folders/00/71bxx4k17bdbgdqtr4ng1w4c0000gn/T/ipykernel_7721/2316639243.py:51: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['Zone'].replace('T', 7, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Treat NaN\n",
    "\n",
    "test['HomePlanet']= test['HomePlanet'].replace('Earth',0)\n",
    "test['HomePlanet']= test['HomePlanet'].replace('Mars',1)\n",
    "test['HomePlanet']= test['HomePlanet'].replace('Europa',2)\n",
    "test['HomePlanet'] = test['HomePlanet'].fillna(1)\n",
    "\n",
    "test['CryoSleep'] = test['CryoSleep'].fillna(test.apply(lambda row: False if any(row[amenities] > 0) else True, axis=1))\n",
    "test['CryoSleep'] = test['CryoSleep'].astype(bool)\n",
    "\n",
    "test['Destination']= test['Destination'].replace('TRAPPIST-1e',0)\n",
    "test['Destination']= test['Destination'].replace('55 Cancri e',1)\n",
    "test['Destination']= test['Destination'].replace('PSO J318.5-22',2)\n",
    "test['Destination'].value_counts()\n",
    "\n",
    "test['Destination'] = test['Destination'].fillna(0)\n",
    "\n",
    "test['age_group'] = np.where(pd.isna(test['Age']), np.nan, np.where(test['Age'] < 18, 0, 1))\n",
    "test['age_group'] = test['age_group'].fillna(1)\n",
    "test.drop(columns=['Age'],inplace=True)\n",
    "\n",
    "test['VIP'] = test['VIP'].fillna(0)\n",
    "test['VIP'] = test['VIP'].astype(int)\n",
    "\n",
    "test['Side'] = test['Side'].replace('S',0)\n",
    "test['Side'] = test['Side'].replace('P',1)\n",
    "\n",
    "# Mitad 0, mitad 1 debido a que la distribución en todas las variables es casi idéntica\n",
    "nan_indices = test[test['Side'].isna()].index\n",
    "\n",
    "# Convertir los índices a una lista para hacerlos mutables\n",
    "nan_indices_list = list(nan_indices)\n",
    "\n",
    "# Mezclar aleatoriamente los índices\n",
    "np.random.shuffle(nan_indices_list)\n",
    "\n",
    "# Dividir los índices en dos mitades\n",
    "half = len(nan_indices_list) // 2\n",
    "\n",
    "# Asignar 0 a la primera mitad y 1 a la segunda mitad\n",
    "test.loc[nan_indices_list[:half], 'Side'] = 0\n",
    "test.loc[nan_indices_list[half:], 'Side'] = 1\n",
    "\n",
    "test['Zone'].replace('G', 0, inplace=True)\n",
    "test['Zone'].replace('F', 1, inplace=True)\n",
    "test['Zone'].replace('E', 2, inplace=True)\n",
    "test['Zone'].replace('D', 3, inplace=True)\n",
    "test['Zone'].replace('B', 4, inplace=True)\n",
    "test['Zone'].replace('A', 5, inplace=True)\n",
    "test['Zone'].replace('C', 6, inplace=True)\n",
    "test['Zone'].replace('T', 7, inplace=True)\n",
    "\n",
    "zone_means = {\n",
    "    0: np.array([71.439625, 78.076592, 69.087143, 87.917937, 74.513873]),\n",
    "    1: np.array([302.185755, 142.406586, 234.280243, 161.430565, 142.463135]),\n",
    "    2: np.array([306.692922, 263.061644, 226.280822, 265.131279, 237.606164]),\n",
    "    3: np.array([660.018828, 581.583682, 305.476987, 460.830544, 281.610879]),\n",
    "    4: np.array([84.148909, 1238.555841, 149.083440, 714.468549, 741.576380]),\n",
    "    5: np.array([133.039062, 1541.539062, 110.062500, 693.250000, 924.414062]),\n",
    "    6: np.array([178.016064, 1788.607764, 171.340027, 905.384203, 1062.558233]),\n",
    "    7: np.array([427.2, 1397.4, 0.4, 2008.4, 883.0])\n",
    "}\n",
    "\n",
    "# Calcular la suma de las amenidades para las filas con Zone NaN\n",
    "test['amenity_sum'] = test[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "\n",
    "# Para las filas con Zone NaN, asignar la zona basada en la cercanía a los promedios\n",
    "def assign_zone(row):\n",
    "    if pd.isna(row['Zone']):\n",
    "        amenity_values = row[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].values\n",
    "        # Calcular la distancia euclidiana entre los pagos y los promedios de cada zona\n",
    "        distances = {zone: np.linalg.norm(amenity_values - means) for zone, means in zone_means.items()}\n",
    "        # Asignar la zona con la menor distancia\n",
    "        return min(distances, key=distances.get)\n",
    "    return row['Zone']\n",
    "\n",
    "# Aplicar la función para asignar las zonas\n",
    "test['Zone'] = test.apply(assign_zone, axis=1)\n",
    "\n",
    "test.drop(columns=['Seat','amenity_sum'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Amenities</th>\n",
       "      <th>GroupId</th>\n",
       "      <th>PassengerNumber</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Side</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>7418.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9266</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>9269</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9271</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>9273</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9277</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Destination  VIP  RoomService  FoodCourt  \\\n",
       "0            0.0       True          0.0    0          0.0        0.0   \n",
       "1            0.0      False          0.0    0          0.0        9.0   \n",
       "2            2.0       True          1.0    0          0.0        0.0   \n",
       "3            2.0      False          0.0    0          0.0     6652.0   \n",
       "4            0.0      False          0.0    0         10.0        0.0   \n",
       "...          ...        ...          ...  ...          ...        ...   \n",
       "4272         0.0       True          0.0    0          0.0        0.0   \n",
       "4273         0.0      False          0.0    0          0.0      847.0   \n",
       "4274         1.0       True          1.0    0          0.0        0.0   \n",
       "4275         2.0      False          0.0    0          0.0     2680.0   \n",
       "4276         0.0       True          2.0    0          0.0        0.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  Amenities  GroupId  PassengerNumber  Zone  \\\n",
       "0              0.0     0.0     0.0        0.0       13                1   0.0   \n",
       "1              0.0  2823.0     0.0     2832.0       18                1   1.0   \n",
       "2              0.0     0.0     0.0        0.0       19                1   6.0   \n",
       "3              0.0   181.0   585.0     7418.0       21                1   6.0   \n",
       "4            635.0     0.0     0.0      645.0       23                1   1.0   \n",
       "...            ...     ...     ...        ...      ...              ...   ...   \n",
       "4272           0.0     0.0     0.0        0.0     9266                2   0.0   \n",
       "4273          17.0    10.0   144.0     1018.0     9269                1   2.0   \n",
       "4274           0.0     0.0     0.0        0.0     9271                1   3.0   \n",
       "4275           0.0     0.0   523.0     3203.0     9273                1   3.0   \n",
       "4276           0.0     0.0     0.0        0.0     9277                1   0.0   \n",
       "\n",
       "      Side  age_group  \n",
       "0      0.0        1.0  \n",
       "1      0.0        1.0  \n",
       "2      0.0        1.0  \n",
       "3      0.0        1.0  \n",
       "4      0.0        1.0  \n",
       "...    ...        ...  \n",
       "4272   0.0        1.0  \n",
       "4273   0.0        1.0  \n",
       "4274   1.0        1.0  \n",
       "4275   1.0        1.0  \n",
       "4276   0.0        1.0  \n",
       "\n",
       "[4277 rows x 15 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4277"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = voting_clf.predict(test)\n",
    "final_preds = preds.astype(bool)\n",
    "len(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(final_preds)\n",
    "ids = pd.read_csv('test.csv')\n",
    "ids = ids[['PassengerId']]\n",
    "ids['Transported'] = final_preds\n",
    "ids.to_csv('preds_more_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0.80617 en Kaggle**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
